{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7 \n",
    "\n",
    "## Grade: /100 pts\n",
    "\n",
    "This notebook contains the questions for Assignment 7. \n",
    "\n",
    "Make sure to complete this assignment individually and appropriately reference all external code and documentation used. ***In order for your submission to be valid, you must adhere to the function definitions which have been made (failure to do so will result in a grade of 0). You must upload this completed Jupyter Notebook file as your submission (other file types are not permitted and will result in a grade of 0).*** You are responsible for selecting and importing additional packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "Feel free to add any libraries to the Preliminaries. However, be mindful of every question's restrictions as some may exclude use of some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform the necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.metrics import recall_score, make_scorer, mean_squared_error, confusion_matrix, precision_score, roc_curve, auc, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "\n",
    "In this Assignment you need to download and use \"Dataset.csv\". \n",
    "\n",
    "This dataset is a modified dataset from Kaggle datasets called \"Lower Back Pain Symptoms Dataset\". Lower back pain can be caused by a variety of problems with any parts of the complex, interconnected network of spinal muscles, nerves, bones, discs or tendons in the lumbar spine.\n",
    "This data set is about to identify/label a person as abnormal or normal using collected physical spine details/data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Load Datasets (15pts)\n",
    "\n",
    "A) Load the \"Dataset.csv\" file.\n",
    "\n",
    "B) Encode the output classes `Label` (0: Normal, 1: Abnormal) and separate inputs and outputs (features and target). (2 pts)\n",
    "\n",
    "C) Split the data into equals-sized training and test sets. Use a random_state = 42, and ensure the `balanced distribution` of labels when splitting data.  \n",
    "\n",
    "D) How many observations do you have in your training set?  \n",
    "\n",
    "E) How many observations for each class in your training set?\n",
    "\n",
    "F) Z-standarize the input features of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Logistic Regression (15 pts)\n",
    "\n",
    "A) Build a L1-regularized logistic regression model to all the training data, and then get the predicted labels for each item of the test set. Tip: use the 'saga' solver for L1 regularization.\n",
    "\n",
    "B) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "C) Print out the model execution time (both training and test time) in milliseconds. Please keep two decimal places.\n",
    "\n",
    "D) Plot ROC curve and report the area under the ROC curve for the test data set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question3: Neural Network \n",
    "\n",
    "\n",
    "### Q3a) Building model (15 pts)\n",
    "\n",
    "Build a simple neural network model (NN_model1) using PyTorch packages with the features in the data set as the input units and two output units for the two output classes:\n",
    "\n",
    "* Use a LogSigmoid as your output non-linearity.\n",
    "* Use the Cross-entropy loss as a training criterion. \n",
    "* Use Stochastic gradient descent optimizer with a learning rate of 0.01. \n",
    "* Run the optimization for 8000 iterations and record the loss for each iteration. \n",
    "* Plot the loss versus iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3b) Prediction (20 pts)\n",
    "\n",
    "Now use your trained model (NN_model1) to make predictions on the test set.\n",
    "\n",
    "A) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "B) Print out the model execution time (both training and test time) in milliseconds. Please keep two decimal places.\n",
    "\n",
    "C) Plot ROC curve and report the area under the ROC curve for the test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3c) Adding hidden layers (15 pts)\n",
    "Change the neural network (NN_model2) and add two hidden layers with 100 and 60 units, respectively. Use the LogSigmoid non-linearity for the hidden layers. Leave all the other parameters the same as for Question 3a. Again train for 8000 iterations and plot the loss as a function of the iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3d) Prediction and model selection (20 pts)\n",
    "Now use your trained model in Question 3c (NN_model2) to make predictions on the test set.\n",
    "\n",
    "A) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "B) Print out the model execution time (both training and test time) in milliseconds. Please keep two decimal places.\n",
    "\n",
    "C) Plot ROC curve and report the area under the ROC curve for the test data set. \n",
    "\n",
    "__Written answer:__ Compare this model (NN_model2) to the results from Question 2 (Logistic Regression) and 3b (NN_model1), what do you conclude? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Written answer:__ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
